//
//  FaceDetectionController.swift
//  UnluckyDraw
//
//  Created on 2025-06-16
//

import Foundation
import Vision
import UIKit
import CoreImage
import AVFoundation
import AudioToolbox

class FaceDetectionController: ObservableObject {
    @Published var detectedFaces: [DetectedFace] = []
    @Published var editableFaces: [EditableFace] = []  // üÜï Ìé∏Ïßë Í∞ÄÎä•Ìïú ÏñºÍµ¥ Î™©Î°ù
    @Published var isProcessing = false
    @Published var error: FaceDetectionError?
    @Published var currentImageSize: CGSize = .zero    // üÜï ÌòÑÏû¨ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞
    
    private var faceDetectionRequest: VNDetectFaceRectanglesRequest?
    private var originalImage: UIImage?  // üÜï ÏàòÎèô Î∞ïÏä§ ÌÅ¨Î°≠Ïö© ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû•
    
    enum FaceDetectionError: LocalizedError {
        case noFacesDetected
        case processingFailed
        case invalidImage
        
        var errorDescription: String? {
            switch self {
            case .noFacesDetected:
                return "No faces detected in the image"
            case .processingFailed:
                return "Failed to process the image"
            case .invalidImage:
                return "Invalid image provided"
            }
        }
    }
    
    init() {
        setupFaceDetection()
    }
    
    private func setupFaceDetection() {
        faceDetectionRequest = VNDetectFaceRectanglesRequest { [weak self] request, error in
            DispatchQueue.main.async {
                self?.processFaceDetectionResults(request: request, error: error)
            }
        }
        
        // ÏµúÎåÄ ÏÑ±Îä•ÏúºÎ°ú ÏñºÍµ¥ Ïù∏Ïãù ÏÑ§Ï†ï
        faceDetectionRequest?.revision = VNDetectFaceRectanglesRequestRevision3
        
        // GPU Í∞ÄÏÜç ÏÇ¨Ïö© Î∞è ÏÑ±Îä• ÏµúÏ†ÅÌôî
        if #available(iOS 14.0, *) {
            faceDetectionRequest?.usesCPUOnly = false // GPU Í∞ÄÏÜç ÌôúÏö©
        }
        
        print("ü§ñ Face Detection initialized with max performance settings")
    }
    
    func detectFaces(in image: UIImage) {
        guard let cgImage = image.cgImage else {
            self.error = .invalidImage
            return
        }
        
        isProcessing = true
        error = nil
        detectedFaces.removeAll()
        
        print("üîç Processing image for face detection:")
        print("  Original size: \(image.size)")
        print("  Original orientation: \(image.imageOrientation.rawValue)")
        
        // Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨Îäî Í∑∏ÎåÄÎ°ú Ïú†ÏßÄÌïòÏßÄÎßå, Î∞©Ìñ• Ï†ïÎ≥¥Î•º Î≥¥Ï°¥
        let processedImage = preprocessImageForDetection(cgImage)
        
        // VisionÏù¥ Ïù¥ÎØ∏ÏßÄ Î∞©Ìñ•ÏùÑ ÏûêÎèôÏúºÎ°ú Ï≤òÎ¶¨ÌïòÎèÑÎ°ù ÏÑ§Ï†ï
        let imageOrientation = cgImageOrientationFromUIImage(image.imageOrientation)
        
        let imageRequestHandler = VNImageRequestHandler(
            cgImage: processedImage,
            orientation: imageOrientation, // Ï§ëÏöî: ÏõêÎ≥∏ Î∞©Ìñ• Ï†ïÎ≥¥ Ï†ÑÎã¨
            options: [:]
        )
        
        print("üîç Vision processing with orientation: \(imageOrientation.rawValue)")
        
        // ‚≠êÔ∏è ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄÎ•º Ï†ÄÏû• (ÎÇòÏ§ëÏóê ÏñºÍµ¥ ÌÅ¨Î°≠Ïö©)
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            guard let request = self?.faceDetectionRequest else { return }
            
            do {
                try imageRequestHandler.perform([request])
                
                // ‚≠êÔ∏è Vision Ï≤òÎ¶¨ ÏôÑÎ£å ÌõÑ Î™®Îì† ÏñºÍµ¥ ÌÅ¨Î°≠
                DispatchQueue.main.async {
                    self?.originalImage = image  // üÜï ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄ Ï†ÄÏû•
                    self?.cropAllDetectedFaces(from: image)
                    
                    // üÜï Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Í∞Ä ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÎã§Î©¥ Ï¶âÏãú editableFacesÎ°ú Î≥ÄÌôò
                    if self?.currentImageSize != .zero {
                        self?.convertToEditableFaces(imageSize: self?.currentImageSize ?? .zero)
                    }
                }
            } catch {
                DispatchQueue.main.async {
                    print("‚ùå Face detection failed: \(error)")
                    self?.error = .processingFailed
                    self?.isProcessing = false
                }
            }
        }
    }
    
    // UIImage.OrientationÏùÑ CGImagePropertyOrientationÏúºÎ°ú Î≥ÄÌôò
    private func cgImageOrientationFromUIImage(_ uiOrientation: UIImage.Orientation) -> CGImagePropertyOrientation {
        switch uiOrientation {
        case .up: return .up
        case .down: return .down
        case .left: return .left
        case .right: return .right
        case .upMirrored: return .upMirrored
        case .downMirrored: return .downMirrored
        case .leftMirrored: return .leftMirrored
        case .rightMirrored: return .rightMirrored
        @unknown default: return .up
        }
    }
    
    private func preprocessImageForDetection(_ cgImage: CGImage) -> CGImage {
        let context = CIContext(options: [.useSoftwareRenderer: false]) // GPU ÏÇ¨Ïö©
        let ciImage = CIImage(cgImage: cgImage)
        
        // Îã§Îã®Í≥Ñ Ïù¥ÎØ∏ÏßÄ Ìñ•ÏÉÅ ÌååÏù¥ÌîÑÎùºÏù∏
        
        // 1Îã®Í≥Ñ: Í∏∞Î≥∏ ÏÉâÏÉÅ Î≥¥Ï†ï
        let colorCorrected = ciImage
            .applyingFilter("CIColorControls", parameters: [
                "inputContrast": 1.3,      // ÎåÄÎπÑ Ï¶ùÍ∞Ä
                "inputBrightness": 0.15,   // Î∞ùÍ∏∞ ÏïΩÍ∞Ñ Ï¶ùÍ∞Ä
                "inputSaturation": 0.8     // Ï±ÑÎèÑ ÏïΩÍ∞Ñ Í∞êÏÜå
            ])
        
        // 2Îã®Í≥Ñ: ÏÉ§ÌîÑÎãù (ÏñºÍµ¥ Ïú§Í≥Ω ÏÑ†Î™ÖÌïòÍ≤å)
        let sharpened = colorCorrected
            .applyingFilter("CISharpenLuminance", parameters: [
                "inputSharpness": 0.7
            ])
        
        // 3Îã®Í≥Ñ: ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞
        let denoised = sharpened
            .applyingFilter("CINoiseReduction", parameters: [
                "inputNoiseLevel": 0.02,
                "inputSharpness": 0.9
            ])
        
        // 4Îã®Í≥Ñ: Í∞êÎßà Î≥¥Ï†ï (ÏñºÍµ¥ ÏòÅÏó≠ Î™ÖÌôïÌïòÍ≤å)
        let gammaAdjusted = denoised
            .applyingFilter("CIGammaAdjust", parameters: [
                "inputPower": 0.85
            ])
        
        // 5Îã®Í≥Ñ: ÏÉâÏò® Ï†ïÍ∑úÌôî (ÏûêÏó∞Ïä§Îü¨Ïö¥ ÌîºÎ∂ÄÌÜ§ Ïó∞Ï∂ú)
        let temperatureAdjusted = gammaAdjusted
            .applyingFilter("CITemperatureAndTint", parameters: [
                "inputNeutral": CIVector(x: 6500, y: 0),
                "inputTargetNeutral": CIVector(x: 6500, y: 0)
            ])
        
        // ÏµúÏ¢Ö Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±
        if let outputCGImage = context.createCGImage(temperatureAdjusted, from: temperatureAdjusted.extent) {
            print("‚ú® Image preprocessing completed with \(outputCGImage.width)x\(outputCGImage.height) resolution")
            return outputCGImage
        }
        
        print("‚ö†Ô∏è Image preprocessing failed, using original")
        return cgImage
    }
    
    private func processFaceDetectionResults(request: VNRequest, error: Error?) {
        defer { isProcessing = false }
        
        if let error = error {
            self.error = .processingFailed
            print("Face detection error: \(error.localizedDescription)")
            return
        }
        
        guard let results = request.results as? [VNFaceObservation] else {
            self.error = .processingFailed
            return
        }
        
        if results.isEmpty {
            self.error = .noFacesDetected
            print("‚ö†Ô∏è No faces detected in image")
            return
        }
        
        // Ïã†Î¢∞ÎèÑ Î∞è ÌÅ¨Í∏∞ Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ (Îçî ÏóÑÍ≤©Ìïú Í∏∞Ï§Ä)
        let faces = results.compactMap { observation -> DetectedFace? in
            let boundingBox = observation.boundingBox
            let confidence = observation.confidence
            
            // 1. Ïã†Î¢∞ÎèÑ Í≤ÄÏÇ¨ (Îçî ÏóÑÍ≤©ÌïòÍ≤å)
            guard confidence > 0.4 else {
                print("‚ùå Rejected face with low confidence: \(String(format: "%.2f", confidence))")
                return nil
            }
            
            // 2. ÏñºÍµ¥ ÌÅ¨Í∏∞ Í≤ÄÏÇ¨ (ÎÑàÎ¨¥ ÏûëÏùÄ ÏñºÍµ¥ Ï†úÏô∏)
            let faceArea = boundingBox.width * boundingBox.height
            guard faceArea > 0.01 else { // Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄÏùò 1% Ïù¥ÏÉÅ
                print("‚ùå Rejected face with small area: \(String(format: "%.4f", faceArea))")
                return nil
            }
            
            // 3. ÏñºÍµ¥ ÎπÑÏú® Í≤ÄÏÇ¨ (ÎÑàÎ¨¥ Í∏∏Í±∞ÎÇò ÎÑ©ÏùÄ ÏñºÍµ¥ Ï†úÏô∏)
            let aspectRatio = boundingBox.width / boundingBox.height
            guard aspectRatio > 0.5 && aspectRatio < 2.0 else {
                print("‚ùå Rejected face with invalid aspect ratio: \(String(format: "%.2f", aspectRatio))")
                return nil
            }
            
            // 4. ÏñºÍµ¥ ÏúÑÏπò Í≤ÄÏÇ¨ (Ïù¥ÎØ∏ÏßÄ Î∞ñÏúºÎ°ú ÎÑàÎ¨¥ ÎßéÏù¥ ÎÇòÍ∞Ñ ÏñºÍµ¥ Ï†úÏô∏)
            guard boundingBox.minX >= -0.1 && boundingBox.maxX <= 1.1 &&
                  boundingBox.minY >= -0.1 && boundingBox.maxY <= 1.1 else {
                print("‚ùå Rejected face outside image bounds")
                return nil
            }
            
            // ‚≠êÔ∏è Vision Ï¢åÌëúÍ≥ÑÎ•º Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ (YÏ∂ï Î≥ÄÌôòÌïòÏßÄ ÏïäÏùå)
            let face = DetectedFace(
                boundingBox: boundingBox, // Vision ÏõêÎ≥∏ Ï¢åÌëú Í∑∏ÎåÄÎ°ú Ï†ÄÏû•
                confidence: confidence
            )
            
            print("‚úÖ Accepted face: confidence=\(String(format: "%.2f", confidence)), area=\(String(format: "%.4f", faceArea)), ratio=\(String(format: "%.2f", aspectRatio))")
            
            return face
        }
        
        // ÌïÑÌÑ∞ÎßÅ ÌõÑÏóêÎèÑ ÏñºÍµ¥Ïù¥ ÏóÜÏúºÎ©¥ ÏóêÎü¨
        if faces.isEmpty {
            self.error = .noFacesDetected
            print("‚ö†Ô∏è No valid faces found after filtering")
            if !results.isEmpty {
                print("  Original detections were filtered out due to quality criteria")
            }
            return
        }
        
        // üé∞ ÏõêÎûò Î°úÏßÅ Ïú†ÏßÄÌïòÎêò, UIÎßå Ï†êÏßÑÏ†ÅÏúºÎ°ú ÏóÖÎç∞Ïù¥Ìä∏
        self.detectedFaces = faces
        
        // UI Ïï†ÎãàÎ©îÏù¥ÏÖòÏùÑ ÏúÑÌïú Î≥ÑÎèÑ Ï≤òÎ¶¨ (Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞Îäî Í∑∏ÎåÄÎ°ú)
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
            // ÎßàÏßÄÎßâÏóê ÏôÑÎ£å ÏÇ¨Ïö¥ÎìúÎßå
            SoundManager.shared.playCompleteSound()
        }
        
        // ÎîîÎ≤ÑÍπÖ Ï†ïÎ≥¥ Ï∂úÎ†•
        print("üéØ Face Detection Results:")
        print("  ‚Ä¢ Total detected: \(results.count)")
        print("  ‚Ä¢ Filtered faces: \(faces.count)")
        
        for (index, face) in faces.enumerated() {
            print("  Face \(index + 1): confidence=\(String(format: "%.2f", face.confidence)), area=\(String(format: "%.4f", face.boundingBox.width * face.boundingBox.height))")
        }
        
        print("‚úÖ Face detection completed successfully")
    }
    
    // ‚≠êÔ∏è ÏôÑÏ†ÑÌûà ÏÉàÎ°úÏö¥ ÏñºÍµ¥ ÌÅ¨Î°≠ ÏãúÏä§ÌÖú
    private func cropAllDetectedFaces(from originalImage: UIImage) {
        print("‚úÇÔ∏è Starting advanced face cropping for \(detectedFaces.count) faces")
        
        // Ïù¥ÎØ∏ÏßÄÎ•º Ï†ïÍ∑úÌôîÎêú Î∞©Ìñ•ÏúºÎ°ú Î≥ÄÌôò
        let normalizedImage = normalizeImageOrientation(originalImage)
        
        // Î™®Îì† ÏñºÍµ¥ÏùÑ ÌÅ¨Î°≠ÌïòÏó¨ Ï†ÄÏû•
        for (index, face) in detectedFaces.enumerated() {
            if let croppedImage = advancedFaceCrop(from: normalizedImage, face: face) {
                detectedFaces[index].croppedImage = croppedImage
                print("‚úÖ Face \(index + 1) cropped successfully: \(croppedImage.size)")
            } else {
                print("‚ùå Failed to crop face \(index + 1)")
            }
        }
        
        print("üéâ Advanced face cropping completed! Ready for roulette!")
    }
    
    // Ïù¥ÎØ∏ÏßÄ Î∞©Ìñ•ÏùÑ Ï†ïÍ∑úÌôî (Ìï≠ÏÉÅ .up ÏÉÅÌÉúÎ°ú ÎßåÎì§Í∏∞)
    private func normalizeImageOrientation(_ image: UIImage) -> UIImage {
        // Ïù¥ÎØ∏ÏßÄÍ∞Ä Ïù¥ÎØ∏ Ï†ïÏÉÅ Î∞©Ìñ•Ïù¥Î©¥ Í∑∏ÎåÄÎ°ú Î∞òÌôò
        if image.imageOrientation == .up {
            return image
        }
        
        // Ï†ïÍ∑úÌôîÎêú ÌÅ¨Í∏∞ Í≥ÑÏÇ∞
        let normalizedSize = CGSize(
            width: image.size.width,
            height: image.size.height
        )
        
        // Ï†ïÍ∑úÌôîÎêú Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±
        UIGraphicsBeginImageContextWithOptions(normalizedSize, false, image.scale)
        defer { UIGraphicsEndImageContext() }
        
        image.draw(in: CGRect(origin: .zero, size: normalizedSize))
        
        if let normalizedImage = UIGraphicsGetImageFromCurrentImageContext() {
            print("üìê Image orientation normalized: \(image.imageOrientation.rawValue) ‚Üí \(normalizedImage.imageOrientation.rawValue)")
            return normalizedImage
        }
        
        print("‚ö†Ô∏è Failed to normalize image orientation, using original")
        return image
    }
    
    // Í≥†Í∏â ÏñºÍµ¥ ÌÅ¨Î°≠ Ìï®Ïàò
    private func advancedFaceCrop(from image: UIImage, face: DetectedFace) -> UIImage? {
        guard let cgImage = image.cgImage else {
            print("‚ùå Cannot get CGImage from UIImage")
            return nil
        }
        
        let imageWidth = CGFloat(cgImage.width)
        let imageHeight = CGFloat(cgImage.height)
        
        print("üîç Image dimensions: \(imageWidth) x \(imageHeight)")
        print("üîç Vision bounding box: \(face.boundingBox)")
        
        // Vision Ï¢åÌëúÍ≥ÑÎ•º CGImage Ï¢åÌëúÍ≥ÑÎ°ú Î≥ÄÌôò
        // Vision: Ï¢åÌïòÎã® ÏõêÏ†ê (0,0), YÏ∂ï ÏúÑÏ™ΩÏù¥ +
        // CGImage: Ï¢åÏÉÅÎã® ÏõêÏ†ê (0,0), YÏ∂ï ÏïÑÎûòÏ™ΩÏù¥ +
        let visionBox = face.boundingBox
        
        let cgBox = CGRect(
            x: visionBox.minX * imageWidth,
            y: (1.0 - visionBox.maxY) * imageHeight, // YÏ∂ï Îí§ÏßëÍ∏∞
            width: visionBox.width * imageWidth,
            height: visionBox.height * imageHeight
        )
        
        print("üîç Converted CGImage box: \(cgBox)")
        
        // ÏñºÍµ¥ ÏòÅÏó≠ÏùÑ 20% ÌôïÏû• (ÏïàÏ†ÑÌïòÍ≥† ÏûêÏó∞Ïä§Îü¨Ïö¥ ÌÅ¨Î°≠)
        let expandRatio: CGFloat = 0.2
        let expandX = cgBox.width * expandRatio
        let expandY = cgBox.height * expandRatio
        
        let expandedBox = CGRect(
            x: max(0, cgBox.minX - expandX),
            y: max(0, cgBox.minY - expandY),
            width: min(imageWidth - max(0, cgBox.minX - expandX), cgBox.width + expandX * 2),
            height: min(imageHeight - max(0, cgBox.minY - expandY), cgBox.height + expandY * 2)
        )
        
        print("üîç Expanded box: \(expandedBox)")
        
        // Í≤ΩÍ≥Ñ Í≤ÄÏÇ¨
        guard expandedBox.width > 0 && expandedBox.height > 0 &&
              expandedBox.minX >= 0 && expandedBox.minY >= 0 &&
              expandedBox.maxX <= imageWidth && expandedBox.maxY <= imageHeight else {
            print("‚ùå Invalid crop box dimensions or out of bounds")
            return nil
        }
        
        // Ïù¥ÎØ∏ÏßÄ ÌÅ¨Î°≠
        guard let croppedCGImage = cgImage.cropping(to: expandedBox) else {
            print("‚ùå Failed to crop CGImage")
            return nil
        }
        
        // ÌÅ¨Î°≠Îêú Ïù¥ÎØ∏ÏßÄÍ∞Ä ÎÑàÎ¨¥ ÏûëÏúºÎ©¥ ÌôïÎåÄ
        let minSize: CGFloat = 200
        let croppedImage = UIImage(cgImage: croppedCGImage, scale: 1.0, orientation: .up)
        
        if max(croppedImage.size.width, croppedImage.size.height) < minSize {
            let scale = minSize / max(croppedImage.size.width, croppedImage.size.height)
            let newSize = CGSize(
                width: croppedImage.size.width * scale,
                height: croppedImage.size.height * scale
            )
            
            UIGraphicsBeginImageContextWithOptions(newSize, false, 1.0)
            defer { UIGraphicsEndImageContext() }
            
            croppedImage.draw(in: CGRect(origin: .zero, size: newSize))
            
            if let scaledImage = UIGraphicsGetImageFromCurrentImageContext() {
                print("üîç Face image scaled up to: \(scaledImage.size)")
                return scaledImage
            }
        }
        
        print("üîç Final cropped face size: \(croppedImage.size)")
        return croppedImage
    }
    
    func clearResults() {
        detectedFaces.removeAll()
        editableFaces.removeAll()
        error = nil
        isProcessing = false
        currentImageSize = .zero
    }
    
    // MARK: - üÜï ÏñºÍµ¥ Ìé∏Ïßë Í∏∞Îä•
    
    /// ÏñºÍµ¥ Ïù∏Ïãù Í≤∞Í≥ºÎ•º Ìé∏Ïßë Í∞ÄÎä•Ìïú ÏñºÍµ¥Î°ú Î≥ÄÌôò
    func convertToEditableFaces(imageSize: CGSize) {
        currentImageSize = imageSize
        editableFaces = detectedFaces.map { face in
            EditableFace(from: face, imageSize: imageSize)
        }
        
        print("üìù Converted \(detectedFaces.count) detected faces to editable faces")
        print("üìù Image size: \(imageSize)")
    }
    
    /// ÏÉàÎ°úÏö¥ ÏñºÍµ¥ Î∞ïÏä§ Ï∂îÍ∞Ä (Ìñ•ÏÉÅÎêú Î≤ÑÏ†Ñ)
    func addNewFace() {
        guard currentImageSize != .zero else {
            print("‚ö†Ô∏è Cannot add face: image size not set")
            return
        }
        
        // Îçî ÎòëÎòëÌïú ÌÅ¨Í∏∞ Í≥ÑÏÇ∞
        let smartSize = calculateSmartBoxSize()
        let suggestedPosition = EditableFace.suggestPosition(
            for: smartSize,
            in: currentImageSize,
            avoiding: editableFaces
        )
        
        var newFace = EditableFace(
            boundingBox: CGRect(
                origin: suggestedPosition,
                size: smartSize
            ),
            confidence: 1.0,
            isUserAdded: true
        )
        
        // üÜï ÏàòÎèô Î∞ïÏä§ Ï∂îÍ∞Ä Ïãú Ï¶âÏãú ÌÅ¨Î°≠ Ïã§Ìñâ
        newFace.croppedImage = cropFaceFromEditableBox(newFace)
        
        editableFaces.append(newFace)
        
        print("‚ûï Added new face box:")
        print("  ‚Ä¢ Position: \(suggestedPosition)")
        print("  ‚Ä¢ Size: \(smartSize)")
        print("  ‚Ä¢ Total faces: \(editableFaces.count)")
        print("  ‚Ä¢ Cropped image: \(newFace.croppedImage != nil ? "‚úÖ" : "‚ùå")")
        
        // ÏãúÍ∞ÅÏ†Å ÌîºÎìúÎ∞±ÏùÑ ÏúÑÌï¥ Ïû†Ïãú ÌïòÏù¥ÎùºÏù¥Ìä∏
        if let newIndex = editableFaces.firstIndex(where: { $0.id == newFace.id }) {
            editableFaces[newIndex].isHighlighted = true
            
            // 2Ï¥à ÌõÑ ÌïòÏù¥ÎùºÏù¥Ìä∏ Ìï¥Ï†ú
            DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) {
                if newIndex < self.editableFaces.count {
                    self.editableFaces[newIndex].isHighlighted = false
                }
            }
        }
    }
    
    /// ÎòëÎòëÌïú Î∞ïÏä§ ÌÅ¨Í∏∞ Í≥ÑÏÇ∞
    private func calculateSmartBoxSize() -> CGSize {
        if editableFaces.isEmpty {
            // Ï≤´ Î≤àÏß∏ Î∞ïÏä§Ïù∏ Í≤ΩÏö∞ Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Ïóê ÎπÑÎ°ÄÌïú Í∏∞Î≥∏ ÌÅ¨Í∏∞
            let defaultRatio: CGFloat = 0.15 // Ïù¥ÎØ∏ÏßÄÏùò 15%
            let size = min(currentImageSize.width, currentImageSize.height) * defaultRatio
            return CGSize(width: size, height: size * 1.2) // ÏïΩÍ∞Ñ ÏÑ∏Î°úÎ°ú Í∏¥ ÌòïÌÉú
        }
        
        // Í∏∞Ï°¥ Î∞ïÏä§Îì§Ïùò ÌèâÍ∑† ÌÅ¨Í∏∞ Í≥ÑÏÇ∞
        let averageSize = EditableFace.averageSize(from: editableFaces)
        
        // ÌÅ¨Í∏∞ Î≤îÏúÑ Ï†úÌïú (ÎÑàÎ¨¥ ÏûëÍ±∞ÎÇò ÌÅ¨ÏßÄ ÏïäÎèÑÎ°ù)
        let minSize: CGFloat = 60
        let maxSize = min(currentImageSize.width, currentImageSize.height) * 0.3
        
        let clampedWidth = max(minSize, min(maxSize, averageSize.width))
        let clampedHeight = max(minSize, min(maxSize, averageSize.height))
        
        return CGSize(width: clampedWidth, height: clampedHeight)
    }
    
    /// ÏñºÍµ¥ Î∞ïÏä§ ÏÇ≠Ï†ú
    func removeFace(withId id: UUID) {
        guard editableFaces.count > 1 else {
            print("‚ö†Ô∏è Cannot remove face: minimum 1 face required")
            return
        }
        
        if let index = editableFaces.firstIndex(where: { $0.id == id }) {
            let removedFace = editableFaces.remove(at: index)
            print("‚ùå Removed face: userAdded=\(removedFace.isUserAdded)")
            print("üìä Total faces: \(editableFaces.count)")
        }
    }
    
    /// ÏñºÍµ¥ Î∞ïÏä§ ÏúÑÏπò ÏóÖÎç∞Ïù¥Ìä∏ (Ìñ•ÏÉÅÎêú Î≤ÑÏ†Ñ)
    func updateFacePosition(id: UUID, dragOffset: CGSize) {
        if let index = editableFaces.firstIndex(where: { $0.id == id }) {
            editableFaces[index].dragOffset = dragOffset
            editableFaces[index].isDragging = true
        }
    }
    
    /// ÎìúÎûòÍ∑∏ ÏôÑÎ£å Ïãú ÏúÑÏπò Ï†ÅÏö© (Ìñ•ÏÉÅÎêú Î≤ÑÏ†Ñ)
    func finalizeFacePosition(id: UUID) {
        if let index = editableFaces.firstIndex(where: { $0.id == id }) {
            // Í∏∞Ï°¥ Î°úÏßÅ Ïú†ÏßÄÌïòÎ©¥ÏÑú Ï∂îÍ∞Ä Í≤ÄÏ¶ù
            editableFaces[index].applyDragOffset()
            editableFaces[index].constrainToImage(size: currentImageSize)
            
            // üÜï ÏÇ¨Ïö©Ïûê Ï∂îÍ∞Ä Î∞ïÏä§Í∞Ä Ïù¥ÎèôÌñàÏúºÎ©¥ Ïû¨ÌÅ¨Î°≠
            if editableFaces[index].isUserAdded {
                editableFaces[index].croppedImage = cropFaceFromEditableBox(editableFaces[index])
                print("üîÑ Re-cropped moved user box: \(editableFaces[index].croppedImage != nil ? "‚úÖ" : "‚ùå")")
            }
            
            let finalBox = editableFaces[index].boundingBox
            print("üìè Finalized face position:")
            print("  ‚Ä¢ Box: \(finalBox)")
            print("  ‚Ä¢ Image bounds: \(currentImageSize)")
            print("  ‚Ä¢ Is within bounds: \(isWithinBounds(finalBox))")
        }
    }
    
    /// Î∞ïÏä§Í∞Ä Ïù¥ÎØ∏ÏßÄ Í≤ΩÍ≥Ñ ÎÇ¥Ïóê ÏûàÎäîÏßÄ ÌôïÏù∏
    private func isWithinBounds(_ box: CGRect) -> Bool {
        let imageBounds = CGRect(origin: .zero, size: currentImageSize)
        return imageBounds.contains(box)
    }
    
    /// Ìé∏ÏßëÎêú ÏñºÍµ¥Îì§ÏùÑ DetectedFace ÌòïÌÉúÎ°ú Î≥ÄÌôò (Î£∞Î†õÏö©)
    func getEditedFacesAsDetected() -> [DetectedFace] {
        return editableFaces.map { editableFace in
            // ÌîΩÏÖÄ Ï¢åÌëúÎ•º Vision Ï¢åÌëúÎ°ú Ïó≠Î≥ÄÌôò
            let visionBox = CGRect(
                x: editableFace.boundingBox.minX / currentImageSize.width,
                y: 1.0 - (editableFace.boundingBox.maxY / currentImageSize.height),
                width: editableFace.boundingBox.width / currentImageSize.width,
                height: editableFace.boundingBox.height / currentImageSize.height
            )
            
            var detectedFace = DetectedFace(
                boundingBox: visionBox,
                confidence: editableFace.confidence
            )
            
            // üÜï ÌÅ¨Î°≠ Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏóÜÏúºÎ©¥ Ï¶âÏÑùÏóêÏÑú ÏÉùÏÑ± (ÏïàÏ†ÑÏû•Ïπò)
            if let croppedImage = editableFace.croppedImage {
                detectedFace.croppedImage = croppedImage
            } else if editableFace.isUserAdded {
                detectedFace.croppedImage = cropFaceFromEditableBox(editableFace)
                print("üîß Emergency crop for user box: \(detectedFace.croppedImage != nil ? "‚úÖ" : "‚ùå")")
            }
            
            return detectedFace
        }
    }
    
    // MARK: - üÜï ÏàòÎèô Î∞ïÏä§ ÌÅ¨Î°≠ ÏãúÏä§ÌÖú
    
    /// EditableFace Î∞ïÏä§ ÏòÅÏó≠ÏùÑ ÏõêÎ≥∏ Ïù¥ÎØ∏ÏßÄÏóêÏÑú ÌÅ¨Î°≠
    private func cropFaceFromEditableBox(_ editableFace: EditableFace) -> UIImage? {
        guard let originalImage = originalImage else {
            print("‚ùå No original image available for cropping")
            return nil
        }
        
        guard let cgImage = originalImage.cgImage else {
            print("‚ùå Cannot get CGImage from original image")
            return nil
        }
        
        let imageWidth = CGFloat(cgImage.width)
        let imageHeight = CGFloat(cgImage.height)
        let boxInPixels = editableFace.boundingBox
        
        print("‚úÇÔ∏è Cropping user box:")
        print("  ‚Ä¢ Original image: \(imageWidth) x \(imageHeight)")
        print("  ‚Ä¢ Display size: \(currentImageSize)")
        print("  ‚Ä¢ Box in display: \(boxInPixels)")
        
        // ÎîîÏä§ÌîåÎ†àÏù¥ Ï¢åÌëúÎ•º Ïã§Ï†ú Ïù¥ÎØ∏ÏßÄ Ï¢åÌëúÎ°ú Î≥ÄÌôò
        let scaleX = imageWidth / currentImageSize.width
        let scaleY = imageHeight / currentImageSize.height
        
        let cropBox = CGRect(
            x: boxInPixels.minX * scaleX,
            y: boxInPixels.minY * scaleY,
            width: boxInPixels.width * scaleX,
            height: boxInPixels.height * scaleY
        )
        
        print("  ‚Ä¢ Crop box in image: \(cropBox)")
        
        // Í≤ΩÍ≥Ñ Í≤ÄÏÇ¨
        let safeCropBox = CGRect(
            x: max(0, cropBox.minX),
            y: max(0, cropBox.minY),
            width: min(imageWidth - max(0, cropBox.minX), cropBox.width),
            height: min(imageHeight - max(0, cropBox.minY), cropBox.height)
        )
        
        guard safeCropBox.width > 0 && safeCropBox.height > 0 else {
            print("‚ùå Invalid crop box dimensions")
            return nil
        }
        
        // Ïù¥ÎØ∏ÏßÄ ÌÅ¨Î°≠
        guard let croppedCGImage = cgImage.cropping(to: safeCropBox) else {
            print("‚ùå Failed to crop CGImage")
            return nil
        }
        
        let croppedImage = UIImage(cgImage: croppedCGImage, scale: 1.0, orientation: .up)
        print("  ‚Ä¢ Cropped size: \(croppedImage.size)")
        
        return croppedImage
    }
}
